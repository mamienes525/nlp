import os
import re
import json
import pandas as pd
import numpy as np
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer, PorterStemmer
import matplotlib.pyplot as plt
from collections import Counter

# ğŸ”§ Ã–n iÅŸleme fonksiyonu
def preprocess_text(text, method="lemmatize"):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    tokenizer = RegexpTokenizer(r'\w+')
    tokens = tokenizer.tokenize(text)

    stop_words = set(stopwords.words("english"))
    tokens = [t for t in tokens if t not in stop_words]

    if method == "lemmatize":
        lemmatizer = WordNetLemmatizer()
        tokens = [lemmatizer.lemmatize(t) for t in tokens]
    elif method == "stem":
        stemmer = PorterStemmer()
        tokens = [stemmer.stem(t) for t in tokens]
    else:
        raise ValueError("Method must be 'lemmatize' or 'stem'")

    return " ".join(tokens)

# ğŸ“Š Zipf eÄŸrisi Ã§izimi
def plot_zipf_curve(csv_path, text_column, title):
    df = pd.read_csv(csv_path)
    words = " ".join(df[text_column].astype(str)).split()
    word_freq = Counter(words)
    sorted_freqs = sorted(word_freq.values(), reverse=True)

    plt.figure()
    plt.plot(range(1, len(sorted_freqs)+1), sorted_freqs)
    plt.xscale('log')
    plt.yscale('log')
    plt.xlabel('Rank (log)')
    plt.ylabel('Frequency (log)')
    plt.title(f"Zipf Plot - {title}")
    plt.grid(True)
    plt.show(block=False)

# âœ… Ã–n iÅŸleme ve CSV oluÅŸturma kontrolÃ¼
def check_and_preprocess_data():
    lemma_csv = "lemmatized_data.csv"
    stem_csv = "stemmed_data.csv"

    if os.path.exists(lemma_csv) and os.path.exists(stem_csv):
        print("âœ… CSV dosyalarÄ± zaten mevcut. Ã–n iÅŸleme atlanÄ±yor.")
    else:
        print("â³ CSV dosyalarÄ± yok. Veri iÅŸleniyor...")

        input_path = "gutenberg_parsed_v1.json"
        with open(input_path, "r", encoding="utf-8") as f:
            books = json.load(f)

        rows = []
        for book in books:
            for chapter in book["chapters"]:
                rows.append({
                    "book_title": book["book_title"],
                    "chapter_title": chapter["title"],
                    "chapter_text": chapter["text"]
                })

        df = pd.DataFrame(rows)

        print("ğŸ” Lemmatization baÅŸlÄ±yor...")
        df["text_lemmatized"] = df["chapter_text"].apply(lambda x: preprocess_text(x, method="lemmatize"))
        print("âœ… Lemmatization tamamlandÄ±.")

        print("ğŸ” Stemming baÅŸlÄ±yor...")
        df["text_stemmed"] = df["chapter_text"].apply(lambda x: preprocess_text(x, method="stem"))
        print("âœ… Stemming tamamlandÄ±.")

        df[["book_title", "chapter_title", "text_lemmatized"]].to_csv(lemma_csv, index=False)
        df[["book_title", "chapter_title", "text_stemmed"]].to_csv(stem_csv, index=False)

        print(f"ğŸ“ Kaydedildi: {lemma_csv} ve {stem_csv}")

    # ğŸ’¡ Zipf grafiklerini her durumda Ã§iz
    print("ğŸ“ˆ Zipf grafik Ã§izimi baÅŸlatÄ±lÄ±yor...")
    plot_zipf_curve(lemma_csv, "text_lemmatized", "Lemmatized Text")
    plot_zipf_curve(stem_csv, "text_stemmed", "Stemmed Text")
    plt.show()

# ğŸš€ Ana giriÅŸ noktasÄ±
def main():
    check_and_preprocess_data()

if __name__ == "__main__":
    main()
