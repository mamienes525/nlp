import os
import re
import requests
import json
from collections import defaultdict

'''
otomatik olarak siteden verileri indirmeyi denedim ancak
ba≈üarisiz olunca kendim manuel olarak indirdim 

import os
import requests

DOWNLOAD_FOLDER = "gutenberg_top20"
BOOK_IDS = [
    84, 2701, 1342, 2542, 64317,
    1513, 11, 844, 43, 174,
    2641, 100, 37106, 145, 2554,
    26184, 345, 98, 16389, 5200
]

os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

VARIANTS = ["-0.txt", "-8.txt", "-4.txt", ".txt", "-0.zip"]

def download_book(book_id, index):
    for variant in VARIANTS:
        file_url = f"https://www.gutenberg.org/files/{book_id}/{book_id}{variant}"
        try:
            response = requests.get(file_url)
            if response.status_code == 200:
                # Zip dosyasƒ±nƒ± es ge√ßiyoruz
                if variant.endswith(".zip"):
                    print(f"[{index}] ‚ö† Found zip for {book_id}, skipping zip.")
                    continue
                if "Project Gutenberg" not in response.text[:500]:
                    continue
                path = os.path.join(DOWNLOAD_FOLDER, f"book_{index}_{book_id}.txt")
                with open(path, "w", encoding="utf-8") as f:
                    f.write(response.text)
                print(f"[{index}] ‚úî Downloaded book {book_id} as {variant}")
                return
        except Exception as e:
            continue
    print(f"[{index}] ‚úñ Failed to download book {book_id}")

# Ba≈ülat
for i, book_id in enumerate(BOOK_IDS, start=1):
    download_book(book_id, i)
'''

# JSON dosyasƒ± daha √∂nce olu≈üturulmu≈ü mu kontrol eder
def check_and_parse_books(cleaned_dir, output_json_path):
    if os.path.exists(output_json_path):
        print(f"üìÅ JSON dosyasƒ± zaten mevcut: {output_json_path} ‚Äî i≈ülemi atlƒ±yorum.")
    else:
        print("üì¶ JSON dosyasƒ± bulunamadƒ±, kitaplar i≈üleniyor...")
        parse_books(cleaned_dir, output_json_path)

#indirilen dosyalarƒ±n txt lerden isimlerini otomatik olarak isimlendiren algoritma
# 1. Dosya adlarƒ±nƒ± ilk satƒ±rdaki ba≈ülƒ±ƒüa g√∂re yeniden adlandƒ±rƒ±r
def rename_books(books_dir):
    renamed_books = {}
    error_books = []

    for original_name in os.listdir(books_dir):
        if not re.match(r'pg\d+\.txt$', original_name):
            continue

        original_path = os.path.join(books_dir, original_name)
        try:
            with open(original_path, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()

            match = re.search(r'Project Gutenberg eBook of (.+?)(?:\.|$)', first_line, re.IGNORECASE)
            if match:
                raw_title = match.group(1)
                clean_title = re.sub(r'[\\/*?:"<>|]', "", raw_title).strip().replace(" ", "_")
                new_name = clean_title + ".txt"
                new_path = os.path.join(books_dir, new_name)
                os.rename(original_path, new_path)
                renamed_books[original_name] = new_name
            else:
                error_books.append((original_name, first_line))
        except Exception as e:
            error_books.append((original_name, str(e)))

    return renamed_books, error_books

# 2. Gutenberg kapanƒ±≈ü metinlerini temizler
def clean_books(books_dir, cleaned_dir):
    os.makedirs(cleaned_dir, exist_ok=True)

    end_markers = [
        r"\*\*\*\s*END OF THE PROJECT GUTENBERG EBOOK.*",
        r"START: FULL LICENSE",
        r"THE FULL PROJECT GUTENBERG LICENSE",
        r"UPDATED EDITIONS WILL REPLACE THE PREVIOUS ONE",
        r"YOU MAY USE THIS EBOOK FOR NEARLY ANY PURPOSE",
        r"PROJECT GUTENBERG‚Ñ¢ ELECTRONIC WORKS",
        r"REDISTRIBUTION IS SUBJECT TO THE TRADEMARK LICENSE"
    ]
    compiled_end_patterns = [re.compile(marker, re.IGNORECASE) for marker in end_markers]

    for fname in os.listdir(books_dir):
        in_path = os.path.join(books_dir, fname)
        out_path = os.path.join(cleaned_dir, fname)

        with open(in_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        cleaned_lines = []
        for line in lines:
            if any(pat.search(line) for pat in compiled_end_patterns):
                break
            cleaned_lines.append(line.rstrip())

        with open(out_path, 'w', encoding='utf-8') as out_f:
            out_f.write("\n".join(cleaned_lines).strip())

# 3. Ba≈ülƒ±ktan b√∂l√ºm numarasƒ± √ßƒ±karƒ±r
def extract_chapter_number(title):
    match = re.match(r'(CHAPTER|CHAP\.|Chapter)\s+([IVXLCDM\d]+)', title, re.IGNORECASE)
    return match.group(2) if match else title.strip()

# 4. Sahte ba≈ülƒ±klarƒ± belirler
def is_fake_chapter(title, text):
    suspicious_titles = [
        "ILLUSTRATIONS", "NOTICE", "EXPLANATORY", "THE AUTHOR", "THE ROYAL NONESUCH",
        "BY ORDER OF", "PER G. G.", "UNKNOWN FRIEND", "AT THE COURT HOUSE",
        "DAVID GARRICK", "EDMUND KEAN", "LADIES AND CHILDREN NOT ADMITTED"
    ]
    title_clean = title.upper().strip()

    if not text.strip():
        return True
    if any(s in title_clean for s in suspicious_titles):
        return True
    if len(text.strip()) < 200 and title_clean.isupper():
        return True
    return False

# 5. Aynƒ± ba≈ülƒ±k tekrarlarƒ±ndan yalnƒ±zca en uzun olanƒ± saklar
def filter_chapter_variants(parsed_books):
    cleaned_books = []

    for book in parsed_books:
        chapter_map = defaultdict(list)

        for chapter in book["chapters"]:
            if is_fake_chapter(chapter["title"], chapter["text"]):
                continue
            chap_num = extract_chapter_number(chapter["title"])
            chapter_map[chap_num].append((len(chapter["text"].strip()), chapter))

        final_chapters = []
        for chap_num, variants in chapter_map.items():
            variants.sort(key=lambda x: x[0], reverse=True)
            final_chapters.append(variants[0][1])

        book["chapters"] = final_chapters
        cleaned_books.append(book)

    return cleaned_books

# 6. Kitaplarƒ± ayrƒ±≈ütƒ±rƒ±r, filtreler, chapter listesi olu≈üturur
# Yardƒ±mcƒ±: Roma rakamlarƒ±nƒ± tam sayƒ±ya √ßevirir
def roman_to_int(roman):
    roman_map = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}
    result, prev = 0, 0
    for c in reversed(roman.upper()):
        value = roman_map.get(c, 0)
        if value < prev:
            result -= value
        else:
            result += value
            prev = value
    return result

# Temizlenmi≈ü dosyalardan kitap + b√∂l√ºmleri ayrƒ±≈ütƒ±rƒ±r
def parse_books(cleaned_dir, output_json_path):
    chapter_header_patterns = [
        r'^\s*CHAPTER\s+[IVXLCDM\d]+',
        r'^\s*Chapter\s+[IVXLCDM\d]+',
        r'^\s*CHAP\.\s+[IVXLCDM\d]+',
        r'^[A-Z ,\'\-\.\?!]{10,}$'
    ]
    compiled_chapter_patterns = [re.compile(pat) for pat in chapter_header_patterns]

    excluded_keywords = ["play", "scene", "drama"]
    parsed_books = []

    for fname in sorted(os.listdir(cleaned_dir)):
        # Tiyatro, drama dosyalarƒ±nƒ± atla
        if any(kw in fname.lower() for kw in excluded_keywords):
            continue

        fpath = os.path.join(cleaned_dir, fname)
        with open(fpath, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f.readlines() if line.strip()]

        # CHAPTER ba≈ülƒ±klarƒ±nƒ±n satƒ±r indekslerini bul
        chapter_indices = [i for i, line in enumerate(lines)
                           if any(pat.match(line) for pat in compiled_chapter_patterns)]

        ###if not chapter_indices:
        ###    continue  # CHAPTER ba≈ülƒ±ƒüƒ± yoksa kitabƒ± atla

        # Giri≈ü kƒ±smƒ± (chapter ba≈ülamadan √∂nceki kƒ±sƒ±m)
        general_description = "\n".join(lines[:chapter_indices[0]])

        # ‚ùó Dil kontrol√º: sadece ƒ∞ngilizce kitaplar i≈ülenir
        if "Language: English" not in general_description:
            continue

        # ‚ùó Yeni: CHAPTER ba≈ülamadan √∂nce CHAPTER kelimesi varsa ‚Üí ba≈üka kitaptan sarkma olabilir
        ###intro_lines = lines[:chapter_indices[0]]
        ###if any("CHAPTER" in line.upper() for line in intro_lines):
        ###    print(f"‚ö†Ô∏è {fname} dosyasƒ±nƒ±n ba≈üƒ±nda ba≈üka kitaptan CHAPTER var. Kitap atlandƒ±.")
        ###    continue

        has_official_chapters = any("CHAPTER" in lines[i].upper() for i in chapter_indices)

        chapters = []
        for i in range(len(chapter_indices)):
            start = chapter_indices[i]
            end = chapter_indices[i + 1] if i + 1 < len(chapter_indices) else len(lines)
            title = lines[start]
            body = "\n".join(lines[start + 1:end]).strip()

            if has_official_chapters and "CHAPTER" not in title.upper():
                continue
            if not body:
                continue

            # ƒ∞lk chapter‚Äôƒ±n doƒüruluƒüunu kontrol et
            if i == 0:
                plain_title = fname.replace("_", " ").replace(".txt", "").lower()
                plain_body = body[:1000].lower()

                chapter_num = 0
                roman_match = re.search(r'CHAPTER\s+([IVXLCDM]+)', title.upper())
                digit_match = re.search(r'CHAPTER\s+(\d+)', title.upper())
                if roman_match:
                    chapter_num = roman_to_int(roman_match.group(1))
                elif digit_match:
                    chapter_num = int(digit_match.group(1))

                if plain_title.split(";")[0] not in plain_body and chapter_num > 50:
                    print(f"‚ö†Ô∏è '{fname}' kitabƒ±nƒ±n ilk b√∂l√ºm√º atlandƒ±: {title}")
                    continue

            chapters.append({"title": title, "text": body})

        if not chapters:
            continue

        parsed_books.append({
            "book_title": fname.replace(".txt", ""),
            "general_description": general_description,
            "chapters": chapters
        })

    # Aynƒ± numaralƒ± ba≈ülƒ±klar varsa kƒ±sa olanƒ± at, sahte ba≈ülƒ±klarƒ± da temizle
    parsed_books = filter_chapter_variants(parsed_books)

    # JSON'a yaz
    with open(output_json_path, "w", encoding="utf-8") as json_f:
        json.dump(parsed_books, json_f, indent=2, ensure_ascii=False)

    print("‚úÖ Kitaplar ba≈üarƒ±yla b√∂l√ºmlere ayrƒ±ldƒ± ve kaydedildi.")

# 7. T√ºm adƒ±mlarƒ± sƒ±rasƒ±yla √ßalƒ±≈ütƒ±ran ana fonksiyon
def main():
    books_dir = "gutenberg_top30"
    cleaned_dir = "gutenberg_top30_cleaned_v1"
    output_json = "gutenberg_parsed_v1.json"

    rename_books(books_dir)                     # 1. Adƒ±m: Dosya adlarƒ±nƒ± d√ºzenle
    clean_books(books_dir, cleaned_dir)         # 2. Adƒ±m: Metinleri temizle
    check_and_parse_books(cleaned_dir, output_json)  # 3. Adƒ±m: JSON varsa ge√ß, yoksa √ºret

if __name__ == "__main__":
    main()

